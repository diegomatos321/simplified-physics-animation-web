\chapter{Otimizações}

A eficiência computacional é um dos fatores determinantes para o desempenho de um motor de física em tempo real. Em jogos, animações interativas, simulações físicas e aplicações gráficas, a necessidade de atualizações contínuas e a obrigatoriedade de operar dentro de limites rigorosos de tempo tornam indispensável o uso de técnicas de otimização em todos os estágios do pipeline de simulação.

Como qualquer objeto pode potencialmente colidir com qualquer outro, uma simulação contendo $n$ objetos requer $(n-1)+(n-2)+\dots+1 = n(n-1)/2 = O(n^2)$ testes de pares no pior caso. Devido à complexidade quadrática, testar ingenuamente cada par torna-se impraticável mesmo para valores moderados de $n$.

Reduzir o custo associado ao teste de pares afetará o tempo de execução apenas linearmente. Para realmente acelerar o processo, o número de pares testados deve ser reduzido. Essa redução é realizada separando o tratamento de colisões de múltiplos objetos em duas fases: \textit{Broad Phase} e \textit{Narrow Phase}.

Neste capítulo, descrevemos as estratégias clássicas de otimização aplicadas à detecção e resolução de colisões, com foco na divisão entre \textit{Broad Phase} e \textit{Narrow Phase}, no uso de estruturas espaciais, na adoção de passos temporais fixos e na execução multi-thread de simulações físicas.

\section{Objetos delimitadores}

Em sistemas de simulação física e detecção de colisões, a representação geométrica dos objetos influencia diretamente a eficiência dos cálculos. Formas complexas, com muitos vértices ou superfícies não convexas, tornam tais testes significativamente mais custosos. Uma solução comum é empregar aproximações convexas que possibilitam testes rápidos sem sacrificar excessivamente a precisão da simulação.

\begin{figure}[htb]
	\centering
	\includesvg[width=0.7\linewidth]{fecho-convexo-interseccao}
	\caption{Em (A) os objetos delimitadores não se intersectam, em (B) eles se intersectam porém os objetos não se intersectam, em (C) eles se intersectam e os objetos se intersectam.}
	\label{fig:fecho-convexo-interseccao}
\end{figure}

A principal motivação para o uso de objetos delimitadores é que formas mais simples (como caixas ou esferas) permitem testes de sobreposição muito mais baratos do que a geometria original que envolvem. Além disso, se eles se intersectam não necessariamente os objetos se intersectam, mas caso não se intersectam necessariamente os objetos não se intersectam, como ilustrado na Figura~\ref{fig:fecho-convexo-interseccao}. Esse fato pode ser usado para acelerar os testes de colisão, como veremos posteriormente. 

Segundo \citeonline{moller2018}, nem todos os objetos geométricos servem como objetos delimitadores eficazes. As propriedades desejáveis para objetos delimitadores incluem:
\begin{itemize}
	\item Testes de interseção de baixo custo
	\item Ajuste preciso
	\item Cálculo econômico
	\item Fácil de girar e transformar
	\item Consome pouca memória
\end{itemize}
como ilustrado na Figura~\ref{fig:formas-fecho-convexo}.

\begin{figure}[htb]
	\caption{Comparação entre objetos delimitadores}
	\centering
	\includesvg[width=\linewidth]{bounding_volumes}
	\caption{Da esquerda para direita esfera delimitadora, caixa delimitadora alinhada aos eixos, caixa delimitadora orientada, K-DOP e fecho convexo.}
	\label{fig:formas-fecho-convexo}
\end{figure}

\subsection*{Esfera Delimitadora}

As esferas constituem o volume delimitador mais simples, definidas apenas por um centro $c$ e um raio $r$:
$$
\text{Sphere} = \{ x \in \mathbb{R}^3 \; | \; \|x - c\| \le r \}.
$$
Testes de colisão entre esferas são rápidos, porém inadequados para objetos de proporções irregulares. Elipsoides oferecem melhor ajuste, mas aumentam o custo de teste. Por isso, essas formas são frequentemente utilizadas em fases preliminares da detecção, ou como nós intermediários em hierarquias de volumes delimitadores (BVH, do inglês \textit{Bouding Volume Hierarchy}).

\subsection*{Caixa Delimitadora Alinhada ao Eixo Coordenado}

A caixa delimitadora alinhada aos eixos (AABB, do inglês \textit{Axis Align Bounding Box}) é um dos objetos delimitadores mais comuns. Trata-se de um paralelepípedo (ou retângulo, em 2D) cujas faces são paralelas aos eixos do sistema de coordenadas. Seu teste de interseção é simples como no Algoritmo~\ref{alg:interseccao-aabb}.
\begin{algorithm}[htb]
	\caption{Teste de Intersecção AABB}
	\KwIn{A e B: volumes AABB}
	\KwOut{Verdadeiro se houver colisão}
	
	\If{$A.x_{max} < B.x_{min}$ \textbf{ou} $A.x_{min} > B.x_{max}$}{
		\Return{False}
	}
	\If{$A.y_{max} < B.y_{min}$ \textbf{ou} $A.y_{min} > B.y_{max}$}{
		\Return{False}
	}
	\If{$A.z_{max} < B.z_{min}$ \textbf{ou} $A.z_{min} > B.z_{max}$}{
		\Return{False}
	}
	\Return{True}
	\label{alg:interseccao-aabb}
\end{algorithm}
% Neste trabalho foram usadas AABBs por serem simples de implementar e eficientes, porém perdem precisão quando o objeto sofre rotações, pois a caixa permanece alinhada aos eixos globais.

\subsection*{Caixa Delimitadora Orientada}

Uma Caixa Delimitadora Orientada (OBB, do inglês \textit{Oriented Bouding Box}) é uma caixa retangular que pode estar arbitrariamente rotacionada em relação aos eixos do sistema de coordenadas. A representação mais comum é feita por um ponto central $c$, por três vetores ortogonais $\hat{u}_i$ que compõem sua orientação e por extensões $e_i$, que são assumidas serem positivas.

OBBs geralmente oferecem melhor ajuste, especialmente para objetos alongados ou rotacionados, reduzindo falsos positivos. Porém, o teste de interseção é mais caro que o das AABBs e geralmente é feito usando o SAT.

\subsection*{Fecho Convexo}

O Fecho Convexo (FC) de um conjunto finito de pontos p é definido como a menor região convexa que contém todos os pontos em p, sendo frequentemente utilizado como um objeto delimitador. Determinar o fecho convexo é um problema recorrente em computação geométrica, especialmente quando se deseja organizar pontos em estruturas mais simples ou acelerar operações posteriores, como testes de colisão.

Existem vários algoritmos, entre os quais o \textit{Quickhull} é um algoritmo bastante conhecido para o cálculo do fecho convexo de um conjunto finito de pontos em qualquer dimensão, adotando uma estratégia de divisão e conquista semelhante ao \textit{quicksort} \cite{barber1996quickhull}.

O Quickhull parte de um conjunto de pontos $S$ e constrói o polígono (ou poliedro) convexo que os contém.  O processo para 2 dimensões é ilustrado na Figura~\ref{fig:quickhull_2d} e pode ser descrito em linhas gerais como no Algoritmo~\ref{alg:quickhull_2d}.
\begin{algorithm}[htb]
	\caption{Quickhull 2D}
	\LinesNumbered
	\SetAlgoLined
	\KwIn{Polígono Convexo}
	\KwOut{Lista dos vértices do fecho convexo}
	
	Encontre os pontos de menor e maior coordenada em $x$; eles pertencem ao fecho convexo.\\
	Use a linha formada pelos dois pontos para dividir o conjunto em dois subconjuntos de pontos, que serão processados de forma recursiva. \\
	Para cada subconjunto, encontre o ponto mais distante da linha; ele forma um triângulo que exclui pontos interiores.\\
	Repita recursivamente os dois passos anteriores nas duas linhas formadas pelos dois novos lados do triângulo. \\
	O processo termina quando todos os subconjuntos estão vazios.
	\label{alg:quickhull_2d}
\end{algorithm}
Apresenta complexidade média $O(n \log n)$ em 2D, podendo chegar a $O(n^2)$ em casos degenerados. Em 3D, adapta-se a construções poliedrais mais complexas, mantendo o mesmo princípio recursivo.

\begin{figure}[htb]
    \centering
    \includegraphics[width=\textwidth]{quickhull_steps.jpg}
    \caption{Etapas do quickjull Fonte: \cite{clustering_explanation2024}.}
    \label{fig:quickhull_2d}
\end{figure}

\section{Filtragem e Refinamento}

Em sistemas de simulação física com muitos objetos, o custo computacional da detecção de colisão pode rapidamente tornar-se inviável. Uma abordagem ingênua, baseada na verificação de todos os pares possíveis de objetos, apresenta complexidade $O(n^2)$, inviável mesmo para quantidades moderadas de entidades dinâmicas. Observa-se, entretanto, que em cenários realistas apenas uma pequena fração dos objetos encontra-se efetivamente próxima o suficiente para colidir em um dado instante. A partir dessa constatação, a detecção de colisão é tradicionalmente decomposta em duas etapas conceitualmente distintas: Filtragem (\textit{Broad Phase}) e Refinamento (\textit{Narrow Phase}).

A etapa de Filtragem tem como objetivo reduzir drasticamente o número de pares candidatos à colisão por meio de testes conservadores e de baixo custo computacional. Nessa fase, não se busca determinar com exatidão se dois objetos colidem, mas apenas descartar, com segurança, aqueles pares cuja colisão é geometricamente impossível. Para isso, empregam-se objetos delimitadores simples, como caixas alinhadas aos eixos (AABB, do inglês \textit{Axis-Aligned Bounding Boxes}), em conjunto com estruturas de localização espacial que exploram a coerência espacial da cena. A premissa fundamental é que objetos só podem interagir se estiverem suficientemente próximos.

As técnicas de partição espacial constituem um dos principais instrumentos da Filtragem. Essas técnicas subdividem o domínio contínuo da simulação em regiões menores, tipicamente convexas, cada uma associada a um conjunto de referências aos objetos que nela se encontram total ou parcialmente. Dois objetos só podem colidir se compartilharem ao menos uma dessas regiões, o que reduz significativamente o número de testes de pares necessários. Tal redução, embora dependente da distribuição espacial dos objetos, permite alcançar tempo esperado próximo de $O(n)$ ou $O(n \log n)$ em cenários bem comportados.

A literatura apresenta diversas estruturas de dados voltadas à organização espacial, incluindo abordagens hierárquicas como \textit{Quadtrees}, \textit{Octrees}, \textit{Binary Space Partitioning Trees} (BSP), \textit{K-d Trees} e \textit{Ball Trees}. As grades uniformes (\textit{Uniform Grids}) constituem um esquema muito usado de subdivisão espacial. 

Uma grade uniforme subdivide o espaço em células de tamanho fixo e igual, associando cada objeto às células que sua caixa delimitadora intercepta, conforme ilustrado na Figura~\ref{fig:grade-uniforme}. Essa abordagem assume implicitamente que a escala dos objetos é relativamente homogênea, hipótese que influencia diretamente sua eficiência.

\begin{figure}[htb]
	\caption{Divisão espacial em grade uniforme}
	\centering
	\includesvg[width=0.5\textwidth]{uniform-grid}
	\label{fig:grade-uniforme}
\end{figure}

Uma implementação direta da grade uniforme poderia empregar uma matriz bidimensional, na qual cada célula armazena uma lista de objetos. Contudo, essa representação apresenta limitações relevantes, como elevado consumo de memória em cenários esparsos, tamanho fixo do mundo e baixa flexibilidade para ambientes potencialmente infinitos. Para contornar essas restrições, adota-se neste trabalho uma abordagem baseada em \textit{hashing espacial}.

Nessa estratégia, cada célula da grade é identificada por coordenadas inteiras $(i, j)$, obtidas a partir das coordenadas contínuas $(x, y)$ do objeto, segundo:
$$
i = \left\lfloor \frac{x}{C} \right\rfloor, \quad
j = \left\lfloor \frac{y}{C} \right\rfloor,
$$
onde $C$ representa o tamanho da célula. As células são mapeadas para uma tabela hash por meio de uma função de espalhamento que combina essas coordenadas inteiras, permitindo armazenar apenas as células efetivamente ocupadas. Cada objeto é inserido em todas as células interceptadas por sua caixa delimitadora, o que garante a propriedade conservadora da Filtragem.

Essa representação permite mapear um espaço de simulação conceitualmente ilimitado em uma estrutura de tamanho controlado, ao custo de possíveis colisões na tabela hash. Tais colisões, entretanto, não comprometem a correção do algoritmo, apenas impactam o desempenho, sendo mitigadas por funções hash adequadas e pelo dimensionamento apropriado da tabela.

Em ambientes dinâmicos, nos quais objetos se movem continuamente e podem ser criados ou removidos, a manutenção incremental da grade torna-se um aspecto crítico. Embora seja possível atualizar apenas as células afetadas por cada objeto em movimento, essa abordagem exige controle adicional e estruturas auxiliares. Neste trabalho, opta-se deliberadamente por uma estratégia mais simples: a grade é completamente reinicializada a cada passo de tempo. Essa decisão representa um trade-off arquitetural, privilegiando simplicidade e previsibilidade de execução em detrimento de possíveis otimizações incrementais, escolha particularmente adequada ao contexto de execução em JavaScript e ambientes baseados na Web.

Uma vez construída a grade, a Filtragem consiste em gerar pares candidatos à colisão a partir dos objetos que compartilham uma mesma célula. Para evitar testes redundantes, é necessário eliminar duplicatas, se dois objetos A e B caem na mesma célula é preciso testar apenas o par (A, B) e não repetir para o par (B, A). Essa etapa é essencial para preservar os ganhos de desempenho proporcionados pela filtragem espacial.

O desempenho de métodos baseados em grade uniforme é fortemente influenciado pela escolha do tamanho da célula. Idealmente, cada objeto deveria ocupar aproximadamente uma única célula; nesse caso, em duas dimensões, um objeto pode interceptar no máximo quatro células adjacentes. Segundo \citeonline{ericson2004real}, escolhas inadequadas para esse parâmetro podem degradar significativamente o desempenho, destacando-se quatro fatores principais:
\begin{enumerate}
	\item células excessivamente pequenas aumentam o custo de atualização da estrutura;
	\item células grandes demais agrupam muitos objetos, reduzindo a eficácia da filtragem;
	\item objetos de geometria complexa podem exigir subdivisão adicional;
	\item cenários com grande variação de escala demandam abordagens hierárquicas ou híbridas.
\end{enumerate}
Assim, a adoção de uma grade uniforme não constitui uma solução universal, mas uma decisão arquitetural dependente das características da cena simulada.

Ao término da Filtragem, obtém-se um conjunto $P$ de pares candidatos à colisão, com redução significativa do custo computacional em relação ao método quadrático. Ainda assim, no pior caso, quando muitos objetos se concentram em uma única célula, a complexidade pode degradar novamente para $O(n^2)$, evidenciando o caráter heurístico dessa etapa.

A etapa de Refinamento realiza testes geométricos precisos nos pares de candidatos P, essa fase é chamada de Narrow Phase. Utiliza-se algoritmos mais sofisticados para determinar se os objetos estão de fato colidindo, como SAT, GJK e EPA, vistos anteriormente. Essa fase nem sempre é obrigatória pois, sua aplicação pode se tratar de objetos retangulares que caibam justamente nas dimensões de sua caixa delimitadora.

\section{Como determinar o intervalo de integração da física}

Em física é preciso estabelecer um valor para o passo de tempo, normalmente chamado de dt (do inglês \textit{Delta Time}). Isso depende muito, se o seu problema tiver muitos objetos e restrito ao tempo, usa-se um dt alto, mas se não estiver restrito ao tempo usa-se o melhor dt possível para obter uma simulação suave. Em muitos casos não é interessante usar todo tempo da máquina para simulação física, mas também para renderização.

No geral existem dois esquemas de integração física. A forma mais simples é usar uma integração de passo fixo usando sempre o mesmo dt e garante que a simulação seja reprodutível. Outra forma é integração com passo variável, ela é a forma mais comum de realizar integração física pois é sempre computada o mais rápido possível olhando o dt depende do tempo decorrido do relógio, o problema disso que dependendo da máquina pode fazer mais passos ou menos passos de simulação, em geral fazer mais passos da simulação trás um resultado mais plausível. 

\section{Execução Paralela e Paralelismo de Dados na Simulação Física}

A simulação física em aplicações interativas apresenta elevado custo computacional, especialmente quando envolve integração temporal, detecção de colisões e resolução iterativa de restrições. No contexto da Web, esse custo torna-se ainda mais relevante devido às limitações da thread principal, responsável não apenas pela execução do código da aplicação, mas também pela renderização gráfica, tratamento de eventos de entrada e atualização da interface do usuário. Dessa forma, torna-se necessário discutir estratégias de paralelismo que permitam manter a responsividade da aplicação sem comprometer a estabilidade e a previsibilidade da simulação física.

% \subsection{Separação entre Simulação Física e Renderização}

Uma abordagem amplamente adotada consiste na separação conceitual entre os processos de renderização e simulação física. Enquanto a renderização é executada na thread principal, geralmente sincronizada com o ciclo de atualização visual por meio de mecanismos como \textit{requestAnimationFrame}, a simulação física pode ser executada em uma thread separada, utilizando \textit{Web Workers}. Essa separação reduz a probabilidade de bloqueios na interface e permite que o cálculo físico seja realizado de forma assíncrona em relação ao processo de desenho.

Nesse modelo, a thread responsável pela simulação apenas escreve o estado físico mais atual e a renderização consome apenas o estado físico mais recente disponível, como ilustrado na Figura~\ref{fig:diagrama-threaded}.

\begin{figure}[htb]
	\centering
	\includesvg[width=\textwidth]{diagrama-threaded}
	\caption{À esquerda esquema tradicional single-thread. À direita esquema com simulação rodando numa thread dedicada a passo fixo.}
	\label{fig:diagrama-threaded}
\end{figure}

% \subsection{Problemas de Programação Concorrente na Simulação Física}

A simulação física apresenta dependências de dados que dificultam sua paralelização completa. Na resolução de colisões e restrições, múltiplas interações podem envolver um mesmo corpo rígido ou partícula. Por exemplo, colisões entre os pares $(A,B)$ e $(B,C)$ compartilham o corpo $B$, o que exige coordenação cuidadosa para evitar inconsistências. No método de Jakobsen, em particular, a ordem de aplicação das restrições influencia o resultado final, tornando a execução paralela ainda mais sensível a variações na ordem de processamento.

Embora a execução da simulação em múltiplas threads pareça uma solução natural para aumentar o desempenho, a programação concorrente introduz uma série de desafios. Um dos principais problemas está relacionado à distribuição de carga (\textit{load balancing}). Em simulações físicas, o custo computacional não é uniforme: regiões do espaço com maior densidade de corpos exigem mais testes de colisão e mais iterações de resolução de restrições, enquanto regiões esparsas demandam pouco processamento. Como essa distribuição varia dinamicamente ao longo do tempo, torna-se difícil dividir o trabalho de forma equilibrada entre várias threads.

Outro desafio fundamental refere-se à consistência dos dados. Em um ambiente multithread, diferentes threads podem acessar e modificar simultaneamente os mesmos estados físicos, como posições e orientações dos corpos. Essa situação pode levar a condições de corrida, resultados inconsistentes e instabilidade numérica. Em simulações físicas, utilizar estados parcialmente atualizados é particularmente problemático, pois pequenas inconsistências podem se propagar e amplificar ao longo das iterações.

Além disso, a necessidade de mecanismos de sincronização, como travas (\textit{locks}), operações atômicas e barreiras, introduz sobrecarga adicional e pode reduzir significativamente os ganhos esperados com o paralelismo. Em muitos casos, o custo de sincronização supera o benefício obtido com a execução paralela, especialmente quando a granularidade das tarefas é fina, como na resolução individual de colisões.

% \subsection{Dificuldades da Física Multithread}


Outro aspecto relevante é o não-determinismo introduzido pela execução concorrente. A ordem de escalonamento das threads pode variar entre execuções, levando a resultados físicos ligeiramente diferentes mesmo sob condições iniciais idênticas. Esse comportamento dificulta a depuração, a reprodução de simulações e a implementação de funcionalidades como \textit{replays} ou sincronização em aplicações distribuídas.

Por essas razões, muitas engines físicas modernas optam por paralelizar apenas etapas bem definidas e fracamente acopladas da simulação, como a detecção de colisão na fase filtragem, a resolução de colisões na fase de refinamento e a resposta a colisão em um único thread lógico.

% \subsection{Paralelismo de Dados: SIMD como Alternativa}

Nem todo paralelismo está associado à execução em múltiplas threads. O paralelismo de dados, explorado por meio de instruções SIMD (\textit{Single Instruction, Multiple Data}), permite aplicar a mesma operação a múltiplos elementos simultaneamente dentro de um único fluxo de execução. Esse modelo é particularmente adequado para etapas da simulação física que envolvem operações homogêneas sobre grandes conjuntos de dados, como a integração temporal das posições, a atualização de velocidades implícitas e testes simples de colisão.

Ao contrário do paralelismo baseado em threads, SIMD não introduz condições de corrida nem exige mecanismos complexos de sincronização, uma vez que todas as operações ocorrem de forma determinística dentro de um único contexto de execução. No contexto da Web, o suporte a SIMD em WebAssembly permite explorar esse tipo de paralelismo de forma eficiente, desde que os dados estejam organizados em layouts de memória apropriados, como \textit{Structure of Arrays} (SoA).

% \subsection{WebAssembly e Execução Física em Thread Único}

O uso de WebAssembly (WASM) oferece vantagens significativas para a implementação de simulações físicas intensivas. Por possuir tipagem estática, memória linear e maior previsibilidade de desempenho, WASM é mais adequado para laços computacionais intensivos do que JavaScript tradicional. Quando combinado com SIMD, um único thread de execução em WASM pode atingir desempenho comparável ou superior a implementações JavaScript multithread, sem incorrer nos problemas de sincronização e não-determinismo associados à concorrência.

Essa abordagem justifica arquiteturas nas quais a simulação física completa é executada em um único worker utilizando WASM, enquanto a thread principal permanece responsável pela renderização e interação com o usuário. Dessa forma, o paralelismo é explorado verticalmente, por meio de instruções vetoriais e melhor uso do hardware subjacente, em vez de horizontalmente, por meio da criação de múltiplas threads concorrentes.

% \subsection{WebGPU e Paralelismo Massivo}

O WebGPU introduz a possibilidade de explorar paralelismo massivo por meio da GPU, sendo particularmente adequado para tarefas altamente paralelizáveis e com baixo acoplamento entre dados. Na simulação física, isso inclui etapas como a detecção de colisão em fase de filtragem, a construção de grades uniformes e a geração de pares candidatos à colisão. Essas operações envolvem grandes volumes de dados independentes e se beneficiam diretamente do modelo de execução da GPU.

Entretanto, a resolução iterativa de restrições físicas, especialmente em métodos como o de Jakobsen, apresenta dependências complexas que limitam sua adequação à execução na GPU. Assim, o uso de WebGPU deve ser encarado como complementar, e não como substituto direto, da simulação física tradicional executada na CPU.

% \subsection{Arquitetura Híbrida Proposta}

Com base nas considerações discutidas, uma arquitetura híbrida mostra-se mais adequada para simulações físicas simplificadas na Web. Nessa arquitetura, a renderização é realizada na \textit{main thread}, a simulação física principal é executada em um worker dedicado utilizando WebAssembly, e o paralelismo de dados é explorado por meio de SIMD. Opcionalmente, etapas específicas e fracamente acopladas, como a fase ampla da detecção de colisões, podem ser delegadas à GPU via WebGPU.

Essa abordagem reduz a complexidade associada à programação concorrente, melhora a previsibilidade dos resultados e mantém um equilíbrio entre desempenho e robustez, sendo particularmente adequada para aplicações Web interativas e educacionais.

% \subsection{Considerações Finais}
